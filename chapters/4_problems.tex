\chapter{Analysis: Goals and Functional Requirements for Solutions}
\label{ch:analysis2}

This chapter identifies the goals of the project to make it predominant to the existing solutions to protein visualisation on AR application. Then, the functional requirements as well as the non-functional requirements to help achieve these goals are discussed. 

\section{Project Goals}
ProteinAR is an iOS application that visualises the three-dimensional structure of proteins. The project was set with three main goals:

(1) Provide an \textbf{educational experience}: enables download and visualisation of user-specified protein structure with data from RCSB PDB. As in Chapter \ref{ch:litRev}, there are a few existing apps that use AR to visualise protein. However, these apps need to scan a code or an image to display the protein, which creates a significant limitation as the protein needed to be pre-rendered. The apps that allow direct protein structure viewing in 3D by entering proteins names also are available but not in AR. 
Thus, the \emph{\underline{first goal}} of this project is to make it possible for the app to connect to RCBS PDB server, download the protein model, and display it on AR after the user types in the name of the protein. 

(2) Provide an \textbf{entertaining experience}: enables the creation of new proteins by the combining of polypeptide chains. As the existing apps on protein visualisation are more focused on simply displaying the protein, this project is set on bringing entertaining elements into the app by the addition of a mini-game function in which users can create new proteins. 
The \emph{\underline{second goal}} of this project is to enable users to create new proteins from the combination of coils, helices, and sheets. For this project, because of the biological complexity of the quaternary structure protein, the new protein created will be in tertiary form. 

(3) Provide an \textbf{interactive experience}: enables interactions between the user and the protein models or polypeptide chains displayed on the screen. By touching the models, users are able to scale the proteins, move the proteins around, and rotate the proteins. The findings from Chapter \ref{ch:litRev} shows that little effort has been put into interactive elements in existing products. The main function of the products is showing the protein. Therefore, the  \emph{\underline{third goal}} of this project is to enable interaction with the 3D models in AR.

\section{Functional requirements for solutions}
\subsection{Educational purpose: Visualising Protein from RCSB PDB server}
There are a few problems must first be addressed in order to visualise the proteins. 
Firstly, the app needs to be able to send requests to the RCSB PDB server. Secondly, the app needs to be able to download the files from the server. Thirdly, the app needs to be able to track the location of the downloaded files. Finally, the app should be able to open the files and display them as an AR layer on the screen. 
	\subsubsection{Send request and download the files}
As mentioned, the app needs to be able to send information (user input) to the server and retrieve the files. Based on this approach, the first attempt was to use the \emph{POST} and \emph{GET} method. This can be achieved by using \emph{HTTP Request} in Swift. 
\emph{HTTP POST Request} allows the app to post information to the destination URL where the specified embedded method is \emph{POST}. This is achieved by first accessing the website, then inspecting its element to find the action method as well as the parameters needed for in this method. 

Similarly, \emph{HTTP GET Request }allows the app to get information from the destination URL where the method is specified as \emph{GET}. The approach is the same as with \emph{POST}; usually the parameters can be found by inspecting the source code of the website, often under \emph{form action}.

To test the function, \href{https://web.expasy.org/protparam/}{ProtParam} was used as the website only consists of string type data. The URL for both \emph{POST} and \emph{GET} are the same and the methods are in the form action. However, since there is no PDB files on ProtParam, RCSB PDB has to be the data source. On RCSB PDB, the methods of \emph{POST} and \emph{GET} do not exist in the \emph{form action} function. The PDB files are directly downloaded by a separate URL in which the only variable part (parameter) is the name of the protein. Understanding this, ProteinAR uses \emph{URLSesssion} and \emph{downloadTask()}. \emph{URLSession} makes network transfers easy and \emph{downloadTask()} fetches the contents of a specified URL, saves it to a local file and calls a completion handle. The \emph{URLSession} tracks the storing place of the download task while it happens. This will be explained more in Chapter \ref{ch:implementation}.
	
	\subsubsection{Display the file}
When the 	files are downloaded, they are saved in the \emph{.pdb} format. In Swift, when a file is downloaded, it is downloaded to a temporary location, after which it can can be moved to the \emph{Document Directory}. ProteinAR specifies the format of the download by saving it as ``proteinName.pdb". 
The solution to visualise the \emph{.pdb} is to convert it to a \emph{.dae} files and then load it on the \emph{SCN}Scene as a scene. 
In order to load the file, one solution is to use move all downloaded items into the project folder using \emph{moveItem}. However, this affects app performance as the entire content of the project is loaded every time the app is run. The solution that was used in this app is to keep all downloaded files in the \emph{Document Directory}. The file path and file name will be specified so that whenever a model is needed, it will be identified using these attributes. 
For loading the file, there needs to be a converter which converts the downloaded \emph{.pdb} file to \emph{.dae} file. This converter will automatically convert any downloaded \emph{.pdb} file in the \emph{Document Directory} into \emph{.dae} so that it can be loaded as a \emph{SCNScene} in the app. 
Unfortunately, due to technical difficulties as well as time constraints, a converter could not be made and remains the largest avenue for future work on this app. Therefore, to demonstrate the app's functionalities, a sample folder of existing "protein.dae" files is imported. 

 	
\subsection{Entertainment purpose: Create new proteins from combination}
\subsubsection{Add polypeptide chains to screen}
The app needs to be able to display user-selected individual polypeptide chain. There are four types of polypeptide chains: Flex Coil, Rig Coil, Helix, and Sheet. Each polypeptide chain is input into the project as a \emph{.dae} model. In order for these models to be loaded on ARKit, they must be converted into \emph{.scn} files. Each model consists of different nodes: the model, lighting, camera, etc. By using the pre-defined function of \emph{SCNScene}, the 3D models can be loaded into the AR view. By passing  the name of each models as a parameter, only one function is needed to add each of the four different polypeptide chains using four different buttons. 

If a model is loaded on screen and the location is not specified, the model may render off-screen. 
An additional problem can occur when two of the same polypeptide types are loaded: in such an occurrence, the two models will appear in the exact same location with the exact same orientation appearing as if there is in fact only one model on the screen. To solve this problem, the app randomises the orientations of the models every time a new model is added to screen by using the pre-defined function of \emph{eulerAngles} to specify the \emph{SCNVector3} with random x, y, and z.

\subsubsection{Combining polypeptide chains}
After adding individual polypeptide chains to the screen, ProteinAR must be able to combine these chains into proteins. If such a combination exists, then the resulting protein should be displayed. For this to happen, successful combinations of these chains are pre-loaded into the apps in a “Combinations” folder. 
In the code, an empty string array for the protein name is created. Every time a user adds a polypeptide chain to the screen, the name of the protein is appended to the array. After a user clicks the “Try” button to combine the polypeptide chains, the names in the array are concatenated using the \emph{array.joined()} function. The name of the models in the “Combinations” folder have a naming convention so that when the array are joined, the name it generated matches with the name of the models in the “Combinations” folder. See Chapter \ref{ch:implementation} for further details. 

\subsection{Interactive purpose: Interacting with the models}
After the polypeptide chains or the protein models are loaded onto the screen, users should be able to interact with the models by using the touchscreen. To make this happen, \emph{UIGestureRecognizer} was used. There are three types of \emph{Gesture Recognizer} used in ProteinAR:

\begin{table}[h!]
\centering
\begin{tabularx}{\textwidth} {
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X | }
\hline
UI Gesture & Gesture Description & Function in the app \\
\hline
\hline
Pinch Gesture & “A two-fingers gesture that moves the two fingertips closer or farther apart” \parencite{wang_beginning_2018}. & Allows users to scale (zoom in, zoom out) on the model. \\
\hline
Rotation Gesture & “A two-fingers gesture that moves the two fingertips in a circular motion” \parencite{wang_beginning_2018}. & Allows users to rotate the models in any angle. \\
\hline
Pan Gesture & “Press a finger on the screen and then slide it across the screen” \parencite{wang_beginning_2018}. & Allows users to move the models on the screen. \\
\hline
\end{tabularx}
\caption {Interacting Gestures in ProteinAR}
\label{tab:gesture}
\end{table}


\section{Non-functional requirements}
\subsection{Core Data}
Core Data is a popular framework provided by Apple to manage the model layer object in an application. 
Core data can automate solutions to common tasks associated with object life cycle and object graph management, including persistence \parencite{noauthor_core_nodate}. In this app, in order to manage the downloaded PDB files, Core Data is used in which Protein is defined as an \emph{Entity}, having two attributes \emph{name} and \emph{location}, stored as \emph{String}. After the file is downloaded and stored in \emph{Document Directory}, a new \emph{Protein Entity} is saved into Core Data, with two attribute values of \emph{name} and \emph{location}. When a model is called, it will use the specified ``proteinName" name attribute and ``filePath.dae" location attribute to open the file in the app. 
Because there are only two attributes in a \emph{Protein Entity}, it can easily be replaced by using String value directly in the app to call the files. However, taking the future work into consideration, where more attributes can be added to a \emph{Protein Entity} such as molecular weights of protein, number of amino acids in a protein, etc., using Core Data can help managing and displaying all these values more effectively.

\subsection{Constraint}
Although it is not mandatory, the app should be able to run on different iOS devices without problem. As the screen size of different iOS devices are different, if the app was designed on the view of iPhone 11 but run on iPhone 6, the buttons might be off screen or other elements might move around, making it impossible to navigate through the app. This is why constraints are important in developing an iOS app. ProteinAR does not have many elements on the screen at the same time, however, the \emph{Auto Layout} was chosen as the solution for the constraints. Using \emph{Auto Layout}, every new view that is a layer on top of a view is made into a \emph{childView} attaching to the \emph{parentView} which makes it easy for the anchor to be pinched to the \emph{parentView}. \emph{NSLayoutConstraint} was used to keep the elements in place. 

\subsection{Protein combination models and Polypeptide chains models management}
The combinations of polypeptide chains are kept in a “Combination” folder and has a naming convention that makes it easy to find each model. It is the combination of the names of the polypeptides, which makes it possible for the array to be combined into the new names. 

When users tap on the individual polypeptide buttons, the models are displayed distinctively without having to tap on the “Try” button. When the “Try” button is tapped, the models on screen combine. In order to do this, the function to add polypeptide chain is created separatedly. 

\section{Summary}
 There are three main goals the project was set to achieve. The first goal is to allow download and visualisation of protein structures from RCSB. The second goal is to allow new protein structures creation and the third goal is to enable interactions with the structures. For this to happen, a number of functional requirements are needed. These include functions to download the files, display the files, loading models as individual and combination, as well as gesture recognitions. Besides, non-functional requirements are also mentioned such as the use of core data, constraints and models management. 
