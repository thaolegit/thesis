\chapter{Final Conclusion}
\label{ch:conclusion}
In this chapter, project summary with achieved results will be concluded, followed by the ideas of direction for future work.
\section{Conclusion}
This project aimed to bring Augmented Reality technology into biological research by visualising protein structures in AR and allow for user interactions. To achieve this, the iOS app ProteinAR was developed to download PDB files from the RCSB Protein Data Bank and display them in AR environment. ProteinAR also allows interactions, in which users can pinch, rotate, move, or create new proteins from  polypeptide chains. This app was designed using Xcode and written in Swift using ARKit, Apple's relatively new framework for developing app-based AR technology. Three main goals were set for the project: enabling the display of protein models from inputted protein IDs, enabling the creation of new protein models, and enabling user interactions with these models. To do this, the process was divided into minor steps, in which minor functions were written to achieve the goals. Additionally, design principles were integrated with extra functions to ensure the usability of the app. 
ProteinAR succeeded in downloading models from RCSB PDB. Any models that were downloaded and converted (using UCSF Chimera) can be displayed on the AR screen. ProteinAR also made it possible for users to combine polypeptide chains into new protein structures. Whether the models are downloaded or created, users can interact with the protein structure to learn more about them. Compared to existing products on visualising protein models in AR, ProteinAR allows more user interactions, as manipulation of protein structures is enabled, and the function to create new protein models from polypeptide chains is a predominant feature.

However, the project has an outstanding issue that needs to be addressed before the app can reach completion. In displaying the protein models downloaded from RCSB PDB, a conversion function from PDB to Collada file is necessary as the ARKit only allows display of the the Collada file type. Due to time constraint of the project, this remains undeveloped, thus ProteinAR can only display protein models from previously downloaded and converted models. 
Nevertheless, ProteinAR proved that retrieving and displaying data from the RCSB PDB is achievable. The advancement of AR technology signals the potential for ProteinAR to be further developed into an invaluable tool for academics of biology, and for anyone with a curious itch to see the unseeable.

\section{Future Work}
Given the limitations of the project, there is plenty of rooms for improvement with ProteinAR. Furthermore, Augmented Reality technology is relatively new and Apple has been acquiring new companies specialising in AR to update the ARKit framework rapidly, creating further possibilities for the development of the app in the future.

First and foremost, the \textbf{protein real-time visualisation} remains unfinished due to it missing a function to convert the PDB file type to the Collada file type. With this function completed, ProteinAR could become extremely useful in biology class as it displays any protein structure in real time. This should be the main focus of future work.

Secondly, \textbf {new protein creation} can be improved in the following directions:
\begin{itemize}
	\item Currently, the combinations of polypeptide chains are pre-loaded into a folder. In the future, if these combinations can be generated in real time, using a server such as I-TASSER, more combinations can be created not limited only to tertiary but quaternary structures.
	\item The newly created protein, if pre-existing, should link to some information such as its parameter, its function, etc. This can be achieved using POST and GET REQUEST to the available source of information.
	\item The newly created protein should be exportable as a PDB file. This way, it could be used for research purposes.
\end{itemize}

Thirdly, more \textbf{interactive elements} can be added. ProteinAR can integrate Machine Learning and CoreML to control ARKit. There are many ways to implement this. One popular way is to combine image classification and AR to create new experiences by experimenting with hand gesture recognition. Photos of hand poses can be taken then used in training models such as TensorFlow, Keras, Custom Vision. Xcode also has a training interface. The models can be trained so that users can use hand poses to control the protein models. Additionally, the protein models could be made more realistic by allowing the user to bend and twist the nodes of the structure. Currently, ProteinAR only allow users to pinch, rotate and pan the models.
 
Last but not least, \textbf{more functions} can be integrated into the app. Currently, the menu function only links the app to the RCSB home page, with no specific information. These functions can be further customised to be more appropriated and interesting. 


