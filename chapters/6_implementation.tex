\chapter{Project Implementation}
\label{ch:implementation}

\section{Download and Visualise Protein Models}
Due to its complexity, the process to download and visualise protein models will be explained in five steps.
\subsection{Step 1. Set up Core Data (Figure \ref{fig:datamodel} and Figure \ref{fig:subclass})}
First, Core Data is set up by adding a new \emph{Data model} from the \emph{Core Data} section. It is important to add-on the \emph{App delegate} if \emph{Core Data} was added in later in the project because Xcode will not automatically generate those delegate and the database will not be set up. In this app, the database has only one entity with the name of \emph{Protein} which has two \emph{attributes} of \emph{name} and \emph{location}, defined in type \emph{String} as in Figure \ref{fig:datamodel}. After that, \emph{NSManagedObjectSubclass} were created where Protein is defined as a public class in \emph{NSManagedObject} and so as function \emph{fetchRequest}.  In these subclass, the attributes of \emph{name} and \emph{location} are also declared as public variables (refer to Figure \ref{fig:subclass})
 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/datamodel.png}
	\caption{Core Data Entity and attributes}
	\label{fig:datamodel}
\end{figure}

 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/subclass.png}
	\caption{NSManagedObject subclass}
	\label{fig:subclass}
\end{figure}

\subsection{Step 2. Download from RCSB PDB using downloadTask (Figure \ref{fig:download1} and Figure \ref{fig:download2})}
\emph{Download} is the critical function in this process and since it is a long one, the code snippet will show the code in two parts with modification for easy explanation. The full functioning code with alternative options can be found in Appendix A or in the attached source code folder. 

In the code shown in Figure \ref{fig:download1}, the URL to the source file is created. After observing how files are downloaded from RCSB, an URL pattern was found. Instead of using the \emph{GET} method in \emph{action form}, RCSB allows downloading the PDB files directly from an URL. The structure of these URL are the same for all of the different PDB files, starting with the same domain. The file name is the only part that needs to be changed, and it is the protein's name. With this logic, the URL to the source file was constructed using the parameter as the user-input-text to change the file name accordingly. 
 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/download1.png}
	\caption{Download function part 1}
	\label{fig:download1}
\end{figure}

The code snippet in Figure \ref{fig:download2} shows how the code uses \emph{URLSession} and \emph{downloadTask()} to generate the download. \emph{URLSession} provides API for downloading and uploading data to the specified URLs. This API helps performing background downloads. In this code, \emph{default} type of \emph{URLSession} is used instead of \emph{shared} because it allows more freedom of configuration. \emph{URLSessionConfiguration} defines the behaviour policies when the app downloads data from the server. There are a few types of \emph{URL Session Tasks}. In this app, \emph{download task} is used as it retrieves data in the form of a file and supports background downloads. 
The status code of \emph{HTTPURLResponse} is important to be known because if the file cannot be downloaded, the problems could be addressed as there could be different reasons that triggers the unsuccessful downloads: the file does not exist (status code 404), the connection to the server was interrupted (status code 500) or something else is wrong with the code. 
When the code performs its download task, the file is store in a temporary location, as called in the code \emph{temporaryURL}. The file will be moved to an absolute path in the \emph{Document Directory} by using the \emph{File Manager} to remove and move item. In order to keep track of the downloaded files and create an absolute path, the name of the files are pre-defined by \emph{destinationURL} (refer to Figure \ref{fig:download2}). 


 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/download2.png}
	\caption{Download function part 2}
	\label{fig:download2}
\end{figure}


The alternative way is to move the downloaded file into the main app bundle as shown in Figure \ref{fig:movetobundle}. The directory of the main app's bundle is created and the file can be moved by the same \emph{moveItem()} method. In the source code, this alternative way is disable. The reason for this was previously explained: if all the downloaded files are saved into the main app's folder, the app will have to load them all every time it is loaded, making the app heavy and slow. 
 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/movetobundle.png}
	\caption{Alternative: Move downloaded files to main app's folder}
	\label{fig:movetobundle}
\end{figure}


\subsection{Step 3. Assign downloaded files to Core Data (Figure \ref{fig:savefunc})}
Firstly, the \emph{context} is declared by \emph{persistentContainer} and the \emph{proteinManagedObject} is declared by starting with \emph{nil}. 
Then, the function to save \emph{proteinManagedObject} \emph{context} is called inside of the \emph{do} action in the download function (Line 433 -Figure \ref{fig:download2}). The function to save context is displayed in Figure \ref{fig:savefunc}. 
When the download is successful, the attributes of \emph{proteinManagedObject.name} and \emph{proteinManagedObject.location} are saved into the Protein \emph{Entity} as \emph{String}. 
Since \emph{proteinManageObject} is a global variable, it can be accessed anywhere in the code. 
 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/savefunc.png}
	\caption{Save and Assign downloaded file to attributes in Core Data}
	\label{fig:savefunc}
\end{figure}

\subsection{Step 4. Convert PDB file to Collada file}
The process would be completed with a script converting \emph{.pdb} file to \emph{.dae} file type because ARScene only allow loading Collada models as its AR Scene. 
A few solutions were used to solve this problem. One of those is to borrow the converting from PDB to Collada script from UCSF Chimera. Since Chimera was written in Python, its scripts could be run in Swift because Python has a C interface API. However, the problem with this was Chimera is not compatible with iOS in the first place, thus, this solution could not be used. 

OpenBabel was another a solution that was carried out. Unfortunately, OpenBabel is also just compatible to Android and MacOS, not iOS and since, was not able to be implemented. 

RCSB PDB published an article on the releasing of their mobile version in 2015 which can help visualise the PDB file on both iOS and Android, however, as of 2020, it was no longer available on the App Store.

Thus, this remains an unsolved problem of this project.

\subsection{Step 5. Fetch and Visualise PDB files (Figure \ref{fig:displayreal})}

The data which are saved into the Core Data would be fetched using \emph{NSFetchRequestResult} and can be display easily using the attributes assigned into Core Data. If the PDB to Collada converter script can be made, the function could just be as easy as shown in Figure \ref{fig:displayreal}
 \begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/displayreal.png}
	\caption{Function to display protein after being converted into Collada models}
	\label{fig:displayreal}
\end{figure}

Due to the unsolved problem of PDB to Collada converter, the app demo video shows some pre-downloaded protein models to give a complete image of how the app would be done if given more time in the future work.

\section{Create new Protein Models}
\subsection{Step 1. Import and name models (Figure \ref{fig:combinations})}
Since ProteinAR uses ARKit and SceneKit to load the models on, for importing the models, first, a new file of \emph{Scene Catalogue} must be made. In this project, the folder is named “Combinations”. The provided combination model type was in \emph{.dae}, however, to enable smooth loading for SceneKit, the files are converted into \emph{.scn} type. These are named after the polypeptide chains names and their order in creating the combinations. See Figure \ref{fig:combinations} for more details of some examples.
 \begin{figure}[!htp]
	\centering
	\includegraphics[scale=0.7]{images/combinations.png}
	\caption{Combinations of polypeptide chains stored in a folder}
	\label{fig:combinations}
\end{figure}
This naming convention makes it easy to pass as arguments and load models in the following functions. To make the models more appealing, Phong shading is used and the colour of each and every model are randomly picked. 

\subsection{Step 2. Add polypeptide function (Figure \ref{fig:addProteinfunc}, \ref{fig:polypeptidefunc})}
Figure \ref{fig:addProteinfunc} shows the function to add the polypeptides on the screen. In this function, the argument is pre-defined as \emph{String} type and has the name of \emph{name}. In \emph{ARKit}, \emph{SCNScene} is used to load the 3D models. Since all the models have the same format (inside of “Combinations.scnassets” folder and has the “.scn” extension), the models will easily be called by passing the names of the protein as arguments each time a Polypeptide button is pressed, as shown in Figure \ref{fig:polypeptidefunc}. 
The function also add a camera node to the screen at the position of (0, 0, 0) and the position of the models are also fixed by \emph{SCNVector3} to ensure that the models will always appear in front of the camera. One of the problems that users might encounter with using AR technology is that the space is infinity and so the models might be loaded in places that cannot be seen. Thus, it is more user-friendly to make sure the position of the models loaded are visible. The function also uses \emph{eulerAngles} with a random \emph{SCNVector3} to make sure that every time new models are loaded, they are at the same position, but with different rotation so they do not lay on top of each other perfectly, ensuring users that they have already added the same models more than one time. 
\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/addProteinfunc.png}
	\caption{Function to add protein to the screen}
	\label{fig:addProteinfunc}
\end{figure}

\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/polypeptidefunc.png}
	\caption{Actions happen when users press on each Polypeptide Button}
	\label{fig:polypeptidefunc}
\end{figure}


\subsection{Step 3. Create new protein (Figure \ref{fig:clearScreen}, \ref{fig:createProtein})}
To simplify the process, the combinations of protein are not completely new but instead, loaded from the “Combinations” folder and displayed. To create a smooth transition and generate the feeling of joining the polypeptide chains, the process has three small steps. 

\subsubsection{Clear everything off the screen}
Clearing the screen off will make the transition to a new model feels more approved. 
\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/clearScreen.png}
	\caption{Function to clear models off the screen}
	\label{fig:clearScreen}
\end{figure}

As the models are added on the screen as nodes (model node, camera node, light node), simply removing all the node from \emph{ParentNode()} would enable clearing off the screen.

\subsubsection{Load a combination model}
In Figure \ref{fig:polypeptidefunc}, it is shown that every time a button is pressed, besides loading a model onto the screen, it does something else. An empty array variable was declared in the beginning and every time a button is pressed, a value is added to the array. For example, when \emph{fCoil Button} is pressed, “fCoil” is added to the array. These values in the array will then be joined using \emph{array.joined()} in the function to create the combination name as shown in Figure \ref{fig:createProtein}. Without any separator, these joined values will become exactly like the names of models in the “Combinations” folder, which enable the code to run and load the models from there. 
\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/createProtein.png}
	\caption{Function to create a new protein}
	\label{fig:createProtein}
\end{figure}

\subsubsection{Display 3D text}
These functions are called inside of function \emph{createProtein}. If the combination that user created is valid, together with the model, the text will be loaded with “Congratulations”, and followed by the names of the polypeptides in order of input. If the combination that user created is invalid, no model would be loaded and instead, only the 3D text will appear with “Sorry”! The combination of (\emph{user-pressed buttons}) cannot be made. See Appendix A for this function. 

\section{Interactive elements}
\subsection{The three gestures to interact with Protein Models (Figure \ref{fig:pinch})}
ARKit is a very powerful framework as it cuts off a lot of coding work to enable gesture interaction. To enable gesture interactions, the first step is to drag and drop the gesture on \emph{Main storyboard} from the built-in library. The three gestures used in ProteinAR are \emph{Pinch Gesture} , \emph{Rotation Gesture} and \emph{Pan Gesture}. The gestures are initiated by \emph{.state: .change}. As in ProteinAR, the goal of interaction is the full screen, the area of gesture is set to be \emph{SCNView} and \emph{hitTest} is used to run the gesture. 

In the function to generate \emph{Pinch Gesture} as shown in figure \ref{fig:pinch}, \emph{SCNVector3} is used with changeable (x, y, z) set in float. By using the two fingertips, users can zoom in and zoom out on the models. 
\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/pinch.png}
	\caption{Pinch Gesture function}
	\label{fig:pinch}
\end{figure}
The other two functions of rotation and pan gesture are similar to pinch gesture and thus, will not be displayed in code here. The codes can be found in the Appendix A . 

\subsection{Other interactive elements (Figure \ref{fig:taplong}, \ref{fig:objcfunc})}
Although it is not a compulsory requirement of the app, more interactive display will make the UI more appealing, thus, some other gestures and touches are added in the app. This might not seem very obvious but it improves the user experience.
\subsubsection{Gestures Recognizer for button}
For the \emph{Record} button, the two gestures of \emph{Tap} and \emph{Long press} were added. There might be other methods to do this, however, creating two objective-C functions was the simplest solution. For this to work, the button should not be connected to the code as an action, but an outlet. Then, in the \emph{viewDidLoad()}, \emph{GestureRecognizer} can be added to the outlet as shown in Figure \ref{fig:taplong}. These \emph{GestureRecognizer} needs handling, which will be handled in objective-C’s function (refer to Figure \ref{fig:objcfunc})
\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/taplong.png}
	\caption{Add Gesture Recognizer to Button outlet}
	\label{fig:taplong}
\end{figure}
\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/objcfunc.png}
	\caption{Objective-C functions to handle Gesture Recognizer}
	\label{fig:objcfunc}
\end{figure}

\subsubsection{Dismiss subview and keyboard (Figure \ref{fig:dismiss})}
When user finishes reading the guidelines on \emph{Help Screen View} or finishing input in the \emph{textFied}, the sub-screen and the keyboard should be dismissed. For the \emph{Help Screen View}, the solution was to use \emph{UITouch}. This is set so that if users touches every place that is not the \emph{Help Screen View}, the view will be hidden. 
For the keyboard, usually it can just be set with \emph{textFieldShouldEndEditting} after specified \emph{TextFieldDelegate} in the class. However, since in ProteinAR, the whole screen are covered in other \emph{UIGesture}, this did not work. The solution was to set the \emph{Return} key to \emph{Done} key in the \emph{viewDidLoad} and then use the function of \emph{textFieldShouldReturn} to dismiss the keyboard, as shown in Figure \ref{fig:dismiss}.

\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{images/dismiss.png}
	\caption{Others interactive elements}
	\label{fig:dismiss}
\end{figure}

